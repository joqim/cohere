# Cohere Chat App Challenge

A simple app for answering user queries with the Cohere API. This app provides a chat interface where users can ask questions and receive AI-generated responses powered by Cohere's language models. It features both streaming and non-streaming response modes, as well as optional Wikipedia integration for enhanced knowledge retrieval. The app consists of a Flask backend API that handles communication with Cohere's services and a React frontend for the user interface.

## Frontend Challenge Instructions

1. Connect the frontend to the backend API (running on port 3333):

   - Configure the API endpoint URL in your environment
   - Set up API client with proper error handling

2. Build the core chat interface components:

   - Create message input with send button
   - Display message history with user/AI distinction
   - Show typing indicators during AI responses
   - Enable message copy functionality

3. Integrate styling using a CSS framework of your choice:

   - Style chat bubbles and messages distinctly
   - Create responsive layout for all screen sizes
   - Ensure good contrast and readability
   - Style error messages and loading states

4. Implement essential chat UX features:

   - Validate empty messages
   - Auto-scroll to new messages
   - Block send button during processing
   - Enable/disable Wikipedia tool toggle

5. [Bonus] Handle all possible states and errors:

   - Show loading states during API calls
   - Handle stream interruptions gracefully
   - Provide retry mechanisms for failed requests

6. Document your choices and additional steps:
   - Explain UX decisions
   - Document error handling approach
   - List accessibility considerations

**Please fill in the steps above. Do not include implementation details or code snippets in this section.**

## Getting started

### Running the app

1. Make sure you have Python3, pip3, and npm installed
2. Set your `CO_API_KEY` environment variable (you'll be prompted if not set)
3. Run the setup script: `bash run.bash`

### API

The API is built with Python using the [Flask](https://flask.palletsprojects.com/en/stable/) framework. It acts as a middleware between the frontend and Cohere's API, processing user queries and returning AI-generated responses. The API exposes a single POST endpoint at `/chat` that handles both streaming responses and Wikipedia-enhanced queries. The endpoint accepts requests with the following schema:

```TypeScript
{
    content: string,
    stream: boolean,
    use_wikipedia_tool: boolean
}
```

### API Response Format

#### Non-Streaming Response

When `stream: false` is sent in the request, the response is a JSON object:

```json
{
  "response": "The answer text generated by the AI."
}
```

#### Streaming Response

When `stream: true` is sent in the request, the response is a [Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) stream. Each event contains a chunk of the answer as plain text:

```
data: The first part of the answer...

data: The next part of the answer...

...

data: [DONE]
```

- The stream ends with `data: [DONE]`.
- If an error occurs, you may receive: `data: [ERROR]: <error message>`
